{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "Basic tutorial using BeautifulSoup to extract forecast data for a particular city in U.S. from weather.gov website.  \n",
    "Based on <a href=\"https://www.dataquest.io/blog/web-scraping-python-using-beautiful-soup/\" target=\"_blank\">this tutorial</a>.\n",
    "\n",
    "If you are not confident with HTML, you can review the basics of the <a href=\"https://docs.google.com/presentation/d/1GonNbQS5eZUZIHmoM9GuGbDb-F1oOx6l8BMYGRYBbFQ/edit?usp=sharing\" target=\"_blank\">here</a>.\n",
    "\n",
    "Additionally, you will need <a href=\"https://docs.mongodb.com/manual/installation/\" target=\"_blank\">MongoDB</a> to persist scraped data. In addition, you can use <a href=\"https://robomongo.org/\" target=\"_blank\">Robo3T</a> as UI client to access MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 10.2 MB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.1.0-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 8.7 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.2-cp310-cp310-win_amd64.whl (55 kB)\n",
      "     --------------------------------------- 55.3/55.3 KB 70.4 kB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.32.0-py3-none-any.whl (900 kB)\n",
      "     -------------------------------------- 900.8/900.8 KB 8.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.3)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Administrador\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrador\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.32.0 kiwisolver-1.4.2 matplotlib-3.5.1 pillow-9.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the website URL and query parameters for the analysis\n",
    "SITE_URL = \"https://forecast.weather.gov/\"\n",
    "PAGE_URL = \"{site_url}/MapClick.php?lat={lat}&lon={lon}\"\n",
    "LAT = 40.7146\n",
    "LON = -74.0071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "Empty host (or extra comma in host list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creating a connection to MongoDB\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mMongoClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m27017\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m db \u001b[38;5;241m=\u001b[39m client[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m collection \u001b[38;5;241m=\u001b[39m db[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforecast\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\mongo_client.py:721\u001b[0m, in \u001b[0;36mMongoClient.__init__\u001b[1;34m(self, host, port, document_class, tz_aware, connect, type_registry, **kwargs)\u001b[0m\n\u001b[0;32m    719\u001b[0m         fqdn \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfqdn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 721\u001b[0m         seeds\u001b[38;5;241m.\u001b[39mupdate(\u001b[43muri_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_hosts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seeds:\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to specify at least one host\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\uri_parser.py:370\u001b[0m, in \u001b[0;36msplit_hosts\u001b[1;34m(hosts, default_port)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m hosts\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m entity:\n\u001b[1;32m--> 370\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty host (or extra comma in host list).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    371\u001b[0m     port \u001b[38;5;241m=\u001b[39m default_port\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;66;03m# Unix socket entities don't have ports\u001b[39;00m\n",
      "\u001b[1;31mConfigurationError\u001b[0m: Empty host (or extra comma in host list)."
     ]
    }
   ],
   "source": [
    "# Creating a connection to MongoDB\n",
    "client = MongoClient(\"\", 27017)\n",
    "db = client[\"weather\"]\n",
    "collection = db[\"forecast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Downloading and storing in-memory the HTML returned by the weather server\n",
    "page = requests.get(PAGE_URL.format(site_url = SITE_URL, lat = LAT, lon = LON))\n",
    "print(page) # Success making the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML content is passed to BeautifulSoup for scraping analysis\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding by id the tag containing the forecasts\n",
    "seven_day = soup.find(id = \"seven-day-forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags classed with `tombstone-container` contain the different forecast data points\n",
    "forecast_items = seven_day.find_all(class_ = \"tombstone-container\")\n",
    "print(len(forecast_items)) # 9 forecast data points founded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printint the HTML content for today's forecast\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting info from the HTML content for today's forecast\n",
    "\n",
    "period = tonight.find(class_ = \"period-name\").get_text()\n",
    "print(period)\n",
    "\n",
    "short_desc = tonight.find(class_ = \"short-desc\").get_text()\n",
    "print(short_desc)\n",
    "\n",
    "temp = tonight.find(class_ = \"temp\").get_text()\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing to img tag directly by name\n",
    "img = tonight.find(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting and showing a static resource, the image best representing the forecast\n",
    "f = urlopen(SITE_URL + img[\"src\"])\n",
    "a = plt.imread(f)\n",
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting additional metadata from image\n",
    "desc = img[\"title\"]\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducing previous extractions for all data points\n",
    "\n",
    "periods = [pt.get_text() for pt in seven_day.select(\".tombstone-container .period-name\")]\n",
    "print(\"Periods:\", periods)\n",
    "\n",
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "print(\"Short descriptions:\", short_descs)\n",
    "\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "print(\"Temperatures:\",temps)\n",
    "\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "print(\"Descriptions:\", descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming extracted data to a tabular format\n",
    "weather_df = pd.DataFrame({\n",
    "    \"period\": periods,\n",
    "    \"short_desc\": short_descs,\n",
    "    \"temp\": temps,\n",
    "    \"desc\": descs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing tabular forecast data\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning temperature column\n",
    "weather_df[\"temp_num\"] = weather_df[\"temp\"].apply(lambda x: x.split(\" \")[1]).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing data, again\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean forecasted temperature?\n",
    "round(weather_df[\"temp_num\"].mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing some relevant information about forecast weather\n",
    "plt.figure(figsize = (15, 7))\n",
    "plt.bar(weather_df[\"period\"], weather_df[\"temp_num\"])\n",
    "plt.title(\"Forecasted temperature (ÂºF) for next 4 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming df to dict\n",
    "weather_dict = weather_df.to_dict(orient = \"row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing extracted information for further analysis\n",
    "collection.insert_many(weather_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
